{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "api_key = \"\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "class OpenAIChatbot:\n",
    "    def __init__(self,des=\"You are helpful\", model=\"gpt-3.5-turbo-0125\",stateless = False):\n",
    "        self.model = model\n",
    "        self.inst = des\n",
    "        self.messages = [{\"role\": \"system\", \"content\": self.inst}]\n",
    "        self.stateless = stateless\n",
    "        self.cumulative_tokens = 0\n",
    "        self.pre_tokens = 0\n",
    "\n",
    "    def reset_chat(self):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": self.inst}]\n",
    "\n",
    "    def chat(self, user_message, temperature=1, max_tokens=150, frequency_penalty=0, presence_penalty=0,form = \"text\"):\n",
    "        self.add_message(\"user\", user_message)\n",
    "        response = client.chat.completions.create(model=self.model,\n",
    "                                                  messages=self.messages,\n",
    "                                                  temperature=temperature,\n",
    "                                                  max_tokens=max_tokens,\n",
    "                                                  frequency_penalty=frequency_penalty,\n",
    "                                                  presence_penalty=presence_penalty,\n",
    "                                                  response_format={ \"type\": form })\n",
    "        cur_token = response.usage.total_tokens\n",
    "        self.pre_tokens = cur_token\n",
    "        self.cumulative_tokens += cur_token\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        if not self.stateless:\n",
    "            self.add_message(\"assistant\", assistant_message)\n",
    "        else:\n",
    "            self.reset_chat()\n",
    "        print(user_message)\n",
    "        print(assistant_message)\n",
    "        return assistant_message\n",
    "    \n",
    "    def show_tokens(self):\n",
    "        print(f\"cur: {self.pre_tokens}, cumulated: {self.cumulative_tokens}\") \n",
    "    def getTokens(self):\n",
    "        return self.cumulative_tokens\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def create_embedding(self, input_text, embedding_model=\"text-embedding-ada-002\", encoding_format=\"float\"):\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                model=embedding_model,\n",
    "                input=input_text,\n",
    "                encoding_format=encoding_format\n",
    "            )\n",
    "            return response[\"data\"][0][\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_chat_history(self):\n",
    "        return self.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancestors(node, parentDict):\n",
    "    ancestors = []\n",
    "    current_node = node\n",
    "\n",
    "    while current_node in parentDict:\n",
    "        parent = parentDict[current_node]\n",
    "        ancestors.append(parent)\n",
    "        current_node = parent\n",
    "    return ancestors\n",
    "\n",
    "def FindSub(ln,data,bot):\n",
    "    j = json.loads(bot.chat('\\n'.join(ln),form=\"json_object\",temperature=0.9,max_tokens=500))\n",
    "    return j\n",
    "\n",
    "def FindSol(goal,data):\n",
    "    res = ''\n",
    "    s = f'Main Goal: {goal}'\n",
    "    ancestor = ancestors(goal,data['parentDict'])\n",
    "    if ancestor:\n",
    "        s += f',chain of parent goals:{\"->\".join(ancestor)}'\n",
    "    if not data['childDict'].get(goal):\n",
    "        bot = OpenAIChatbot(des='given an objective, you will produce an detailed and concise plan to achieve this goal,straight to the point and nothing else, <120 words',stateless=True)\n",
    "        res = bot.chat(s,form=\"text\",temperature=0.8,max_tokens=2000)\n",
    "        data['tokens'] += bot.getTokens()\n",
    "    else:\n",
    "        children = data['childDict'].get(goal) \n",
    "        for child in children:\n",
    "            s += '\\n'+ child + ':\\n'\n",
    "            s += data['data'][child] \n",
    "        bot = OpenAIChatbot(des='I am solving a problem from a bottom up manner.Given a main goal,the chain of parent goals of it,and several of the sub-goals of the main goal and corresonding plans,merge the plans and produce a coherent, concise and detailed plan to achieve the main goal,<1000 words',stateless=True)\n",
    "        res = bot.chat(s,form=\"text\",temperature=0.8,max_tokens=2000)\n",
    "        data['tokens'] += bot.getTokens()\n",
    "    # rev = revise(res,data)\n",
    "    return res\n",
    "\n",
    "def revise(s,data):\n",
    "    bot = OpenAIChatbot(des='given a plan, improve it and make it more concise',stateless=True)\n",
    "    chat = bot.chat(s,temperature=0.9,max_tokens=700)\n",
    "    data['tokens'] += bot.getTokens()\n",
    "    return chat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.loads(file.read())\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def has_grandparent(node, parent_dict):\n",
    "    parent = parent_dict.get(node)\n",
    "    return parent and parent_dict.get(parent) is not None\n",
    "\n",
    "def divide_phase(data):\n",
    "    if not data['divideQueue']:\n",
    "        return\n",
    "    transition_to_conquer = False\n",
    "    current_level_nodes = data['divideQueue'].copy()\n",
    "    data['divideQueue'].clear()\n",
    "    bot = OpenAIChatbot(des='given one or several objectives,seperated by \"next line\", respond with a json. Divide each objectives into 2 to 3 sub-objectives(should be complete sentenses, no punctuation and period) that are concise and essential,use EXACT original objective name(DO NOT CHANGE ANYTHING) as key and list formed by corresponding sub-objectives as value, no more than 10 words each',stateless=True)\n",
    "    children_j = FindSub(current_level_nodes,data,bot) \n",
    "    data['tokens'] += bot.getTokens()\n",
    "\n",
    "    for parent_node in current_level_nodes:\n",
    "        children = children_j[parent_node]\n",
    "        data['childDict'][parent_node] = children\n",
    "        for child in children:\n",
    "            data['parentDict'][child] = parent_node\n",
    "            if not has_grandparent(child, data['parentDict']):\n",
    "                data['divideQueue'].append(child)\n",
    "            else:\n",
    "                transition_to_conquer = True\n",
    "            data['conquerStack'].append(child)\n",
    "\n",
    "    if transition_to_conquer:\n",
    "        data['isDividing'] = False\n",
    "\n",
    "def conquer_phase(data):\n",
    "    if data['conquerStack']:\n",
    "        current_node = data['conquerStack'].pop()\n",
    "        data['data'][current_node] = FindSol(current_node,data)\n",
    "\n",
    "def main(file_path):\n",
    "    data = load_json(file_path)\n",
    "\n",
    "    if data['isDividing']:\n",
    "        divide_phase(data)\n",
    "    else:\n",
    "        conquer_phase(data)\n",
    "    save_json(data, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'chatState3.txt'\n",
    "emptyJ = {\n",
    "    \"isDividing\": True,\n",
    "    \"divideQueue\": [],\n",
    "    \"tokens\": 0,\n",
    "    \"conquerStack\": [],\n",
    "    \"childDict\": {},\n",
    "    \"parentDict\": {},\n",
    "    \"data\": {}\n",
    "}\n",
    "def startup(topic):\n",
    "    emptyJ['divideQueue'].append(topic)\n",
    "    emptyJ[\"conquerStack\"].append(topic)\n",
    "    save_json(emptyJ,file_path)\n",
    "startup('find out exactly how to create a program that can automate and enhance major parts of the process of formulating a complete plan that achieves a given main objective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    main(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json(file_path)\n",
    "print(list(data['data'].items())[-1][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
